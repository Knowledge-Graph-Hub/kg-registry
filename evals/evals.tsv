ID	Access Level and Types										Provenance of Nodes and Edges														Documented standards, schema, construction										Update frequency and versioning										Evaluation - Metrics and Fitness for Purpose										License Information
	access_otherthanKG_text	access_otherthanKG	api_or_online_access_text	api_or_online_access	multi_access_options_text	multi_access_options	sourcecode_available_text	sourcecode_available	downloadable_KG_text	downloadable_KG	source_list_provided_text	source_list_provided	source_versions_info_text	source_versions_info	import_dependancies_text	import_dependancies	node_edge_sources_text	node_edge_sources	edges_deduplication_text	edges_deduplication	triples_source_details_text	triples_source_details	edge_type_schema_text	edge_type_schema	bio_usable_data_text	bio_usable_data	resolvable_ids_text	resolvable_ids	construction_docs_text	construction_docs	transform_docs_text	transform_docs	schema_used_text	schema_used	stable_versions_text	stable_versions	public_tracker_text	public_tracker	kg_contact_info_text	kg_contact_info	updated_annually_text	updated_annually	prior_versions_access_text	prior_versions_access	use_case_provided_text	use_case_provided	eval_against_others_text	eval_against_others	defined_scope_text	defined_scope	multi_eval_methods_text	multi_eval_methods	accuracy_metrics_text	accuracy_metrics	License_text
pharmkg	Yes - PharmKG provides embeddings, learned low-dimensional representations for entities and relations via KGE models. It also provides top predicted paths for mechanistic interpretation (Fig 6) and t-SNE visualizations showing semantic structure (Fig 5).	Y	N	N	N	N	Yes - The full source code for KG construction, processing, and the Heterogeneous Graph Attention Network (HRGAT) embedding model is provided on the GitHub repository https://github.com/MindRank-Biotech/PharmKG/tree/master	Y	Yes - The benchmark KG is downloadable. They also provide both the clean version (final benchmark) and the raw version (with more entities and relations); the KG dataset is guarded by Google Drive permissions to access it	Y	Yes — An integration of 6 sources (OMIM, DrugBank, PharmGKB, TTD, SIDER, HumanNet); plus entity features from MeSH, PubChem, BioBERT, BioGPS, and Connectivity Map	Y	No - Do mention integrating “recent versions” of each source and give details of ID mapping and unification (e.g., Entrez Gene ID, MeSH hierarchy) but no explicit version numbers or file names for each data dump are shown in the text	N	 Yes - The code is built on Pykeen and KG-reeval, with details for training and hyperparameters. Also mentions use of RDKit for chemical fingerprints and BioBERT for embeddings	Y	Partially - Confirms that nodes were unified with standard IDs (Entrez, MeSH, PubChem) and that duplicate synonyms were resolved, but it doesn’t state that each edge carries explicit source provenance tags — only that relations were merged and thematically assigned using Global Network of Biomedical Relationships (GNBR)	Y	Yes - Explicitly describes merging overlapping triplets, disambiguation with synonym tables, and merging semantically similar relations using clustering 	Y	Yes - Explains how 29 relation types were derived, how Global Network of Biomedical Relationships (GNBR) semantic themes were mapped, and which sources contribute to which entity types and interactions	Y	Yes - Documents edge semantics: “interaction,” “disease-gene,” “chemical-gene,” “disease-chemical,” and subtypes — all mapped from Global Network of Biomedical Relationships (GNBR) semantic themes and curated bases	Y	Yes - All entities explicitly use standard biomedical identifiers and the structure is designed to support drug repurposing, target discovery, adverse reaction prediction, etc., in real-world biomedical tasks	Y	Yes - Genes use Entrez Gene IDs; diseases use MeSH IDs; chemicals use PubChem IDs	Y	Yes - Explains the construction in detail, including entity filtering, merging, disambiguation, feature extraction, and the final schema design	Y	Yes - Removed trivial entities, merged low-level symptoms into MeSH parent diseases, clustered and merged redundant relation types, applied PCA for feature reduction, and explain all steps clearly	Y	Yes - 29 defined relation types with source mapping and entity categories; and semantics from Global Network of Biomedical Relationships (GNBR) themes and curated bases	Y	No - There is no formal semantic versioning scheme mentioned for the dataset or codebase	N	No - There is no mention of a public tracker for feature requests or issues	N	Yes - Two corresponding authors are provided with full institutional contacts (Prof. Yuedong Yang and Dr. Zhangming Niu) in the published paper (https://academic.oup.com/bib/article/22/4/bbaa344/6042240)	Y	No - No evidence yet. They state they plan future expansions (e.g., transcriptomics, clinical data, auto-extraction) but no recurring updates are published so far	N	Partially - They do provide the raw version alongside the final benchmark on GitHub but do not maintain a changelog across multiple yearly versions	Y	Yes - Provide detailed case studies for Alzheimer’s disease and Parkinson’s disease for drug repurposing and target discovery, with literature validation, top scored predictions, and visualized paths 	Y	Yes - Benchmarked Heterogeneous Graph Attention Network (HRGAT) and 9 other KGE baselines on Hetionet and PharmKG side by side and analyzed results 	Y	Yes - The paper is a dedicated benchmark for evaluating KGE models in biomedical relation prediction, with explicit focus on drug repurposing, target identification, and multi-relation prediction tasks	Y	Yes - Link prediction (MRR, Hits@k), downstream tasks (AUROC, AUPRC), t-tests for significance	Y	Yes - Multiple: MRR, Hits@1/3/10/100, AUROC, AUPRC, p-values for statistical tests, plus visualization and interpretability checks with t-SNE plots and path analyses	Y	No explicit license (restricted use). The paper notes: “© The Author(s) 2020. Published by Oxford University Press. All rights reserved.” But does not reveal license information (nor does the GitHub repo)
bioteque 	Y (Bioteque provides node-type-specific embeddings for 11 of the node types in its graph, along with downloadable sets of those individual sets of nodes mapped to their representations in the embeddings.)	Y	N	N	N	N	Y (Source code for assembling the KG is provided in a GitHub repository, https://github.com/sbnb-irb/bioteque. This includes source-specific scripts for retrieving data components.)	Y	N	N	Y (see https://bioteque.irbbarcelona.org/sources)	Y	N	N	Y (The list of data sources is documented and includes specific mentions of source files in its data retrieval scripts, e.g., the source for COSMIC is defined here: https://github.com/sbnb-irb/bioteque/blob/master/datasets/cosmic_mutsig/get_data.sh)	Y	Y (The sources of nodes and edges are provided in the documentation and the node files.)	Y	Y (The 2022 Bioteque paper makes two notes about duplicate resolution: "...we first mapped the samples and genes to our reference vocabulary and collapsed the duplicates by their mean value", and "We mapped the cell lines and genes to our reference vocabularies and took the mean value whenever duplicates occurred".)	Y	Y (The list of data sources is documented and makes specific mention of which associations are derived from which sources; see https://bioteque.irbbarcelona.org/sources)	Y	N	N	Y (the provided node files are provided as TSVs, though assembly of a full KG would require running the graph assembly code. It appears that the assembly code also produces nodes and edges in a TSV format.)	Y	Y (node identifiers are from clearly defined sources and expressed as CURIEs)	Y	Y (Documentation regarding the assembly code is provided; see https://github.com/sbnb-irb/bioteque)	Y	Y (each source has its own transform code and documentation, provided on the GitHub repo, https://github.com/sbnb-irb/bioteque)	Y	N	N	N	N	Y (the GitHub repository at https://github.com/sbnb-irb/bioteque is public and permits issue creation).	Y	Y (it's never explicitly stated as a contact, but the responsible organization, the Structural Bioinformatics and Network Biology Group at the Institute for Research in Biomedicine Barcelona, is identified along with a link to their home page)	Y	N		N	N	Y (Examples of use are described in the 2022 Nat Comm paper; an example of generating predictions for drug repurposing is provided.)	Y	N	N	N	N	Y (Multiple evaluation methods are provided in the 2022 Nat Comm paper, primarily for embedding evaluation.)	Y	Y (Multiple validation methods are provided in the 2022 Nat Comm paper, including two distinct analyses involving gene expression data and protein-protein interactions, respectively.)	Y	CC BY 4.0 
primekg	Yes - ClinicalBERT-based embeddings were used to group disease nodes, providing an embedding-derived version of the graph	Y	N	N	Yes - Available via Harvard Dataverse with raw KG (kg raw.csv) and largest connected component (kg giant.csv) https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IXA7BM 	Y	Yes - Full source code is available on GitHub https://github.com/mims-harvard/PrimeKG 	Y	Yes - Harvard Dataverse Repo hosts the downloadable KG and intermediate files https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IXA7BM 	Y	Yes - 20 primary data sources listed, including DisGeNET, DrugBank, UMLS, Orphanet, etc. in the paper https://www.nature.com/articles/s41597-023-01960-3 	Y	Yes - Explicit versions and download dates provided for each dataset in the Methods/Data Records section	Y	Partially - Tools like goatools, beautifulsoup, regex scripts, and vocabulary mappings are mentioned in the GitHub repo, but not all formal dependencies are listed	Y	Yes - Each node contains node source; edges are annotated by type and origin	Y	Yes - Duplicates and self-loops were removed during KG preprocessing and merging	Y	Yes - Clear documentation on what triples were derived from which resource (e.g., drug–protein from DrugBank, phenotype–disease from HPO)	Y	Yes - The paper documented schema of 30 edge types and their origin ontologies	Y	Yes - Clinical and pharmacological text features are readable and interpretable (e.g., Mayo Clinic descriptions, DrugBank pharmacodynamics)	Y	Yes - Uses Mondo, DrugBank, HPO, MeSH, Entrez Gene IDs, and UMLS CUIs, which are mappable and resolvable via external resources	Y	Yes - Extensive paper + GitHub repo	Y	Yes - Transformations like self-loop removal, duplicate dropping, phenotype-disease resolution, and mapping across ontologies are documented	Y	Yes - Node and edge formats, and their standardized schema, are explained in the methodology and data files	Y	No - No version tags (e.g., v1.0, v1.1) are mentioned or used on Dataverse or GitHub	N	No - GitHub Issues tab is not actively used for public feature requests or bug tracking		Yes - Maintained by Zitnik Lab at Harvard with lab contact and GitHub maintainers listed 	Y	 No - Only one release version is available as of now (May 2022)	N	No - No archived prior versions or changelog indicating updates	N	Yes - Autism case study demonstrates disease concept resolution and clinical alignment	Y	Yes - Compared to other KGs (e.g., SPOKE); benchmarks and references to prior systems included	Y	 Yes - Focused on disease-centric precision medicine with defined coverage: 17,080 diseases, 10 biological scales, 20 sources	Y	Yes – Structure connectivity, edge density, text embedding-based grouping, and clinical relevance tested	Y	Partially - Uses similarity thresholds (e.g., cosine ≥ 0.98 for disease grouping); no formal metrics like precision/recall provided	Y	CC BY 4.0 
hetionet	Yes - Can access paths, DWPCs, prediction probabilities, network support breakdowns for compound–disease pairs (via Neo4j Browser & guides)	Y	Yes - fully hosted on a public Neo4j instance with Cypher queries, guides, tutorials https://neo4j.het.io/browser/ 	Y	Yes - Downloadable as JSON, Neo4j DB, TSV; also query online in Neo4j Browser; source code & intermediate datasets on GitHub, Zenodo, Figshare	Y	Yes, the source code and scripts are public on hetio and GitHub linked in the paper https://github.com/elifesciences-publications/hetionet 	Y	Yes - Multiple export formats (JSON, Neo4j dump, TSV)	Y	Yes - 29 sources documented; each node/edge carries source information in properties; full list with versions in paper https://elifesciences.org/articles/26726 	Y	Yes - Versions noted: e.g., DrugBank v4.2, SIDER v4.1, LINCS L1000 (Oct 2015), Pathway Commons (with date)	Y	Yes - Input ontologies and databases fully listed with versions; also intermediate resources described (e.g., STARGEO, PharmacotherapyDB	Y	Yes - Node/edge properties include URLs, source, license, confidence scores (for applicable edges)	Y	Yes - Merged redundant pathways; multiple studies for same edge consolidated; non-informative gene sets removed	Y	Yes - Explicit per metaedge: e.g., binding affinities (≤1 mM), co-occurrence p-values (MEDLINE), gene interaction specifics	Y	Yes - Clear metagraph with 11 node types & 24 metaedges; each with documented origin & justification	Y	Yes - Uses standard biomedical IDs: Entrez, UMLS, MeSH, DO, Uberon	Y	Yes - Entrez Gene, DOID, MeSH IDs, InChIKeys used for easy cross-referencing	Y	Yes - Extensive: paper + Thinklab logs + GitHub issues + detailed guides	Y	Yes - Explained pruning (e.g., filtering Uberon terms, merging pathways, restricting GO terms by size)	Y	Yes - Metagraph is the explicit schema; node and edge types clearly defined	Y	Partial - “v1.0” labeled, but no formal version history beyond initial	Y	Partial - Thinklab (now static); issues can be filed on GitHub	Y	Yes - Daniel Himmelstein and team, contactable via GitHub, Thinklab archives, paper	Y	No - Only v1.0 publicly released so far	N	No - Early versions mentioned but no archived download versions listed	N	Yes - Nicotine dependence (bupropion), epilepsy predictions (acamprosate)	Y	Yes - Compared to PREDICT, Guney et al., Cheng et al.; used baselines & permutation	Y	Yes - Designed for systematic drug repurposing + broader knowledge integration	Y	Yes - DWPC + AUROC + permutation + cross-validation + external test sets (DrugCentral, ClinicalTrials.gov)	Y	Yes - Probability scores, cross-validated elastic net, path-level contribution breakdowns, AUROC	Y	CC0 1.0
spoke	yes - neighborhood explorer; limited to 10k nodes; API https://spoke.rbvi.ucsf.edu/swagger/	Y	yes - neighborhood explorer; limited to 10k nodes	Y	yes	Y	no	N	no	N	yes in supplemental and on website	Y	yes; pulled each week	Y	no	N	yes https://spoke.rbvi.ucsf.edu/docs/index.html	Y	yes; sort of; genes and protiens are considered different	Y	yes; some for instance specifies PPI for humans comes from STRING; human disease ontology provides disease associated gene	Y	yes 	Y	yes no custom data transforms that are KG specific	Y	yes uses Ensembl	Y	yes edge and node types specified with source	Y	yes; data is downloaded and integrated as is	Y	yes uses Biolink when practical	Y	no	N	no	N	yes email provided	Y	yes updated weekly according to paper	Y	no	N	no	N	no	N	yes; biomedical applications such as drug reuposing, disease prediction, embedding EHR data	Y	no	N	no	N	CC BY 4.0 
gnbr	yes can access themes which relate to the path types and their score	Y	no	N	no	N	no but can get code to process data	N	yes but its very weirdly done; separated into files by edge types	Y	yes - but NLP so not many databases used	Y	yes - pubtator annotations from april 30, 2016	Y	yes detailed dependancy path extraction; 	Y	yes each edge has a lot of information; NLP was used and the sentance that constructed something is listed	Y	yes counted as a co occurance; feature not a bug used to inform network	Y	yes - very limited	Y	yes - NLP; had four interaction types and three node types 	Y	yes all information coming from publications outside of KG	Y	yes uses UMLS IDs for rare diseases	Y	yes specifies where disease and drug nodes come from	Y	yes eliminated paths containing dependencies of type conj	Y	yes self documented and reported with downloads	Y	yes 7 versions available	Y	no	N	no	N	yes but not updated since 2019	Y	yes and indicated which version was used in the paper	Y	yes drug disease indications ; 2 case studies 	Y	yes; compared to gold standard drug indications; relationships from other databases for those gotten using NLP methods	Y	yes drug repurposing 	Y	yes case studies; drug-disease path analysis; validation using DGIdb; used lit review to verify novel drug 	Y	yes performance on gold standard drug indications calculate AUROC; dendrograms of the themes	Y	CC BY 4.0 
ncatsgardkg	Yes – The KG enables extraction of disease mappings, disease profiles, and pathogenesis paths, as shown in the case studies (e.g., 3-hop paths from Wilson disease)	Y	Yes – Public Neo4j instance available: https://disease.ncats.io	Y	N	N	Partially – The in-house framework stitcher is mentioned and linked (https://github.com/ncats/stitcher), but full KG generation scripts for GARD KG are not public	Y	Y (networkx pickle) 	Y	Y, integrates 34 distinct biomedical resources	Y	ORPHADATA v4.0  Gene Ontology  Human Phenotype Ontology  GO annotations Pathway Commons (PTC) Pharos v3.8.0	Y	Partially – Tools like stitcher and OWL file parsing are mentioned, but not declared formally like a software repo would	Y	Yes – each node/edge carries provenance via stitch keys (e.g., N_Name, I_CODE)	Y	Partially – Mappings and harmonization discussed, but no explicit deduplication process for edges described	Y	Yes – Object properties defined per source and integration method (e.g., has_phenotype, I_CODE, N_Name)	Y	Yes – Meta-ontology schema is described with object properties and their meanings (Table 3)	Y	Yes – Disease profiles, drug-disease associations, and harmonization rules demonstrate biomedical applicability	Y	The paper explicitly mentions using "Unique Ingredient Identifier (UNII)," "MONDO ID," and "OMIM ID" for mappings, indicating that external identifiers are a core part of their entity resolution strategy	Y	Yes – Detailed methods section describes data collection, mapping strategies, and harmonization	Y	The paper notes that "data cleanup was performed," mentioning specific examples like restricting prefixes for OMIM IDs and Orphanet IDs. It also discusses the challenges of programmatic annotation, such as preventing the annotation of generic terms like "Disease" or "Syndrome"	Y	The paper outlines a "meta-ontology" that serves as the schema for the knowledge graph. This includes a clear definition of primary classes and object properties used to structure the data; documented in tables 2–4	Y	No	N	No	N	Yes – Corresponding author: qian.zhu@nih.gov and NCATS/ NIH team affiliation listed	Y	Yes - Suggests updates over time; indicates continually updated	N	No	N	Yes – Four detailed case studies: disease mapping, disease profiling, data harmonization, pathogenesis exploration	Y	The paper compares its approach with other similar efforts, such as the semantic Diseasecard and the Monarch Initiative, placing its own work in the context of the broader field; but no explicit benchmarking	Y	Yes – Focused on rare diseases, especially those curated in GARD, and integrating relevant biomedical data	Y	Partially – Demonstrates utility via case studies but lacks formal quantitative evaluation (mapping stats in tables 6,7,10)	Y	The paper's semi-automatic mapping process for FDA orphan designations includes a manual curation step where curators labeled mappings as "Done," "Approximate," or "Failed," providing a clear way to measure the confidence or accuracy of the mappings	Y	CC BY 4.0 
kg-monarch	Yes, can access the mapping schema biolink model which provides sematics mappings and ontological relationships, can access downloadable graph dumps in SciGraph or KGX formats. 	Y	Yes, can access by Monarch's own webpage, API, Neo4j, downloadable Graph. 	Y	Yes, Monarch provides multiple ways to download the data such as KGX TSV, KGX JSON lines, Neo4j Dump, etc. 	Y	Yes, can access the source code for making the KG on Github. 	Y	Yes, KGX TSV, KGX JSON lines, Neo4j Dump, etc. 	Y	Yes, 33 heterogeneous data sources including HPOA, CTD, OMIM, Orphanet, WormBase, FlyBase, MGI, dictyBase, Xenbase, SGD, RGD, PomBase, ZFIN, NCBI, HGNC, Panther, BGeeDB, Reactome, STRING.	Y	Yes, provides the version info of the sources used: https://data.monarchinitiative.org/monarch-kg-dev/latest/index.html	Y	Yes, declared dependencies through its build infrastructure in the monarch-ingest and kg-hub Github repo. Specifically, Monarch uses Poetry for the dependencies management. 	Y	Yes, nodes and edges contain the most upstream source and knowledge provider information. 	Y	Yes, duplicate edge and node management is taken into consideration in the construction of the KG. 	Y	Yes, the triples created are captured in multiple stages of the KG ingest pipeline including the biolink preddicate mappings and the output. 	Y	Yes, Biolink model. All relationships are mapped to Biolink predicates. 	Y	Yes, Monarch KG is both human-readable and usable. Monarch provides its data in tablular formats that are easy to understand. Also, Monarch KG data and its Monarch initaitive webpage can be used in bioinformatics & biomedical analysis, machine learning, NLP, LLMs, visualization & exploration, etc. 	Y	Yes, supports resolvable and externally linked identifiders. Monarch KG uses curie-style IDs that follow identifier conventions and are mappable to URLs for resolution. Also, it includes a column called xref which contains a list of external identifiers. 	Y	Yes, Monarch made great effort to document its KG construction including data ingestion, transformation, schema usage, and KG merging. 	Y	Yes, Monarch documented data transforms including the excluded nodes and dangling edges. 	Y	Yes, Monarch uses a documented schema, Biolink Model, and its monarch-ingest pipeline for construction. 	Y	Yes	Y	Yes, Monarch provides public tracker for feature requests, bug reports on it Github repo. 	Y	Yes, the contact is Monarch Initiative. Contact information is provided. 	Y	Yes, the KG is updated every month. 	Y	Yes, prior versions are accessible. And there is a dashoboard for QC showing what the changes are between any two versions. https://qc.monarchinitiative.org/#monarch?dataset=Development&kgVersion=2025-07-09	Y	Yes, Monarch KG is used in Exomiser which is a tool to annotate variants and has a ChatGPT plugin through RAG to support information search. It is also integrated into the GRAPE library for graph analysis and machine learning. 	Y	No	N	Yes, Monarch aims to harmonize the data across the fields (gene, disease, phenotype across species) to facilitate the discovery of disease mechanism and aid the disease diagnosis. 	Y	Yes, created Monarch Quality Control (QC) Dashboard for quality metrics that are specific to Monarch. In addition, it developed Phenotypic Inference Evaluation Framework (PhEval) to evaluate the analysis of its tool Exomiser. 	Y	Kind of but not explicit. The edge data contains columns like provided_by, publications, and has_evidence to measure the accuracy or confidence. 	Y	CC BY 4.0 
clinicalkg	no	N	yes both	Y	yes; neo4j, docker, csv, python library	Y	yes well documented github https://github.com/MannLabs/CKG?tab=readme-ov-file	Y	yes many different ways	Y	yes in github with links as well as supplemental table S1	Y	no	N	yes in github and documents on how to download and use	Y	yes edges have pubmed identifiers	Y	yes; built in redundancy to assess overlap and disagreememnt of sources	Y	no	N	no	N	yes use all external identifiers; ontolgies 	Y	yes used standardized identifiers for nodes not described with exsiting terminoloies or ontologies	Y	yes well documented in the paper and a github is well done	Y	no	N	yes custom; defined in paper figure 3A	Y	yes three versions 	Y	yes; encouraged through github	Y	yes mann labs	Y	yes; newest is from 2022	Y	yes 	Y	yes; non-alcoholic fatty liver disease; cancer biomarkers; identify theraputic options for chemorefractory cases	Y	yes compared their ability to identify cancer biomarkers with paper from 2018	Y	yes harmonization of proteomics with other omics data	Y	no	N	no	N	C BY-NC 4.0
rtx-kg2	Yes, RTX-KG2 is able to provide various biomedical information through queries. It is also used as backend to support ARAX's path reasoning and path ranking (https://github.com/RTXteam/RTX) . 	Y	Yes, can access by API query, and Neo4j. 	Y	Yes, multiple ways to access including downloadable versions, API (SmartAPI), web browser user interface (seems not currently working). 	Y	Yes, Github (https://github.com/RTXteam/RTX-KG2)	Y	Yes, downloadable versions are available on Github	Y	Yes, 70 sources Table 1 (UMLS, SemMedDB, ChEMBL, DrugBank, Reactome, SMPDB, and 64 additional knowledge sources). 	Y	Yes, it documents the versions of the upstream sources used (https://github.com/RTXteam/RTX-KG2/blob/master/docs/kg2-versions.md). 	Y	Yes, in the requirements file. 	Y	Yes, node's ID contains source information and edge contains primary knowledge source. 	Y	Yes, it provides a pre-canonicalized graph version (RTX-KG2pre, with semantically duplicated concepts) and a canonicalized version (RTX-KG2c, withthout semantically duplicated concepts)	Y	Yes, in the final output KG, each edge includes the source that reated that triple. 	Y	Yes, it uses Biolink Model for as the schema standard for both nodes and edges.	Y	Yes, it is used for other biological applications such as answering translational science questions, drug repositioning, identifying new therapeutic targets, and understanding drug mechanisms. 	Y	Yes, it uses resolvable IDs for the entities. 	Y	Yes, it has clear and step by step documentation on construction on its Github repo	Y	Yes, in Appendix	Y	Yes, Biolink model and extract-transform-load (ETL) approach for construction. 	Y	Yes, it is using semantic versioning (e.g., KG2.7.3)	Y	Yes, provides public tracker for requests, bug reports on it Github repo. 	Y	Yes, it provides contact information of the KG2 Team.	Y	Yes, once per month (mentioned in Discussion). 	Y	Yes, the prior versions are accessible (https://github.com/ncats/translator-lfs-artifacts/blob/main/README.md) with documented changes (https://github.com/RTXteam/RTX-KG2/blob/master/docs/kg2-versions.md). 	Y	Yes, it is currently being used by multiple Translator reasoning agents such as ARAX (Autonomous Relay Agent X).	Y	Yes, it is compared to four other KGs (Hetionet, SPOKE, the SRI Reference Knowledge Graph, and ROBOKOP)	Y	Yes, it is a part of NCATS Biomedical Data Translator project to support automated biomedical reasoning and question answering. It aims to create a semantically standardized, computable, and interoperable biomedical KG that supports translational reasoning and biomedical discovery. 	Y	Yes, it is not only evaluated with other KGs, but also evaluated on the tools that utilize it such as ARAX, mediKanren, BioThings Explorer, and  ARAGORN. 	Y	Yes, the nodes and edges contain evidence, provenance, and other information for measuring accuracy and confidence. 	Y	CC BY 4.0 
hra-kg	Yes, users can ask biological questions via queries (Basic Usage: https://cns-iu.github.io/hra-kg-supporting-information/#basic-usage, Advanced Usage: https://github.com/cns-iu/hra-kg-supporting-information/blob/main/README.md)	Y	Yes, can access by SPARQL endpoint, HRA API, and RESTful-API. 	Y	Yes, dynamic queries through its SPARQL, RESTful-API, and UIs.	Y	Yes, Github (https://github.com/hubmapconsortium/hra-kg)	Y	Yes, available on Zenodo and HRA CDN	Y	Yes, Table 2	Y	Yes, the type, name, and version of each DO is documented (https://lod.humanatlas.io/asct-b/). 	Y	Yes, in the hra-do-processor. 	Y	Yes, both nodes and edges have source information	Y	Not explicit. As each digital object produces its own graph, the triples from different objects may have similar relationships, but they are stored in separate contexts.	N	Yes, the triples are generated by Digital Objects in in RDF format.  	Y	Yes, the KG is built based on RDF graph (CCF ontology) and standard ontologies to define relationship types between the entities. 	Y	Yes, the data is human readable and usable in various biological applications. 	Y	Yes, it uses resolvable IDs for the entity resolution such as UBERON:0013702 and ENSG00000175899. 	Y	Yes, it provides comprehensive documentation on its construction process (HRA KG Construction and Deployment). 	Y	Yes, it documents data transfroms such as data normalization and enrichment. 	Y	Yes, ASCT+B tables and Common Coordinate Framework (CCF) Ontology. 	Y	Yes, e.g., v2.3.	Y	Not explicitly mentioned, but there are multiple Github Issues portals for users to post requests, reports bugs, and discussions. 	N	Yes, contact information is available to reach out to the team (https://humanatlas.io/about#editorial-board)	Y	Yes, about 2 time a year (https://github.com/hubmapconsortium/hra-kg/releases). 	Y	Yes, prior versions are accessible on Github (https://github.com/hubmapconsortium/hra-kg/releases). Changed are documented (https://humanatlas.io/release-notes/v2.3). 	Y	Yes, they have several use cases and applications (Usage Notes). 	Y	No, The HRA-KG is compared with other KGs only from technical perspective, such as the number of nodes, edges, and technologies used. 	Y	Yes, HRA-KG is focused on representing the healthy human body in semantics terms including anatomical structures, cell types, and biomarker and spatial terms such as 3D reference organs. 	Y	Yes, it has hra-ols used by OLS for validation (https://lod.humanatlas.io/collection/hra-ols/latest/) and has Validation report (https://github.com/hubmapconsortium/3d-hra-ref-object-validation) (Supplementary). 	Y	Not explicit, but it has HRAlit which links the HRA DOs to publications, experts, experimental datasets (Supplementary). 	N	CC BY 4.0 
petagraph	yes, portions of the graph that are open licensed are available from https://osf.io/6jtc9/files/osfstorage	Y	yes, (ish), neo4j dump can be downloaded if you have a UMLS license key, and there are instructions to build a neo4j from sources in the github repository. Ish, because it's not specifically hosted, you need to host it yourself.	Y	no, (ish) completed graph can only be downloaded as neo4j, components to build the graph can also be downloaded, but that doesn't quite feel like it makes a yes 	Y	yes, ETL of upstream sources lives in https://github.com/x-atlas-consortia/ubkg-etl/ 	Y	yes (with UMLS api key)	Y	yes, methods section of paper https://www.nature.com/articles/s41597-024-04070-w#Sec2	Y	yes, ish, some source versions listed in https://github.com/TaylorResearchLab/Petagraph/tree/main/Scientific_Data_2024	Y	yes, ubkg etl has requirements.txt, petagraph has requirements-test.txt	Y	Yes. They either come from existing ontologies or have one file per datasource with edges and nodes that are being added.	Y	Yes - Yes. Bidirectional edges are only for Concept–Concept; other edges are unidirectional. Redundancies are minimized using binning and source normalization	Y	Yes, methods of paper	Y	yes custom schema defined in paper	Y	Yes, csv files	Y	Yes, concept CUI with codes corresponding to common external ID/s	Y	Yes, well documented github	Y	guidlines for formatting ontologies in user guide, method explain preprocessing steps	Y	Start with ontologies and standards in the UBKG and add in omics data based on their paper defined in the schema	Y	No, lists date last updated but no version	N	No	N	Yes, contributors listed https://osf.io/6jtc9/ 	Y	Yes, frequent small updates	Y	recent acitivty documents date of all changes and person who made them but prior versions not accessible https://osf.io/6jtc9/ 	Y	Yes, several in paper	Y	No	N	Yes integrating/analyzing multiomics datasets	Y	link prediction tasks auROC, precision-recall, top tissues associated w a disease, and shortest path analysis of subgraphs	Y	Yes. AUC-ROC, Precision-Recall curves, common neighbors vs random, structural metrics compared to randomized graphs	Y	CC BY-NC-ND 4.0
genomickb	Y, can submit an online query and download subgraphs that meet criteria	Y	website with UI for creating queries, API supposely coming in v2, Neo4j dump available but not hosted by creators	Y	Y, can use online query tool or download Neo4j dump	Y	Y, https://github.com/tinalee-tech/KG-dataloader	Y	Y, Neo4j dump	Y	Y, supplementary note 1 	Y	N	N	N	N	Y, tables 1 (nodes)  & 2 (edges), query allows users to restrict by datasource 	Y	Considered but not de-duplicated. Users can restric querys to specific datasources and duplicate edges can be used for validation. EX:  ‘enhancer regulate gene’ with restriction ‘cell_line=GM12878’ and ‘data_source=EnhancerAtlas’ -> 118,610 node pairs. A second query for ‘variant overlap enhancer’, ‘enhancer regulate gene’, and ‘variant correlate_with gene’ ->  16,871  enhancer-gene pairs from EnhancerAtlas can be validated by GTEx eQTLs	Y	Y, table 2	Y	Y, table 2	Y	Y, they have a web interface (https://gkb.dcmb.med.umich.edu/) presenting the entities and edges in a human-readable format. It can be used to answer genomics-related questions and conduct biological analysis	Y	Y, uses one external ID when possible and defines globaly unique IDs for entities without such as ChIP-seq peaks	Y	Y, github and supplement	Y	Y, sup Note 1 Data Collection and Processing	Y	Uses custom schema not an existing one but does provide documentation	Y	Y but still on version 1.0 despite multiple upates listed	Y	N, FAQ says to email the team	N	Y, website has a contacts button with name/emal for both technical details and accessing the data/web server	Y	During 2022-2023 yes but not since then	Y	Clearly documented chages with dates but prior versions not available. *Paper states that they store all versions internally and can revert if unexpected changes are ever made to their graph but these are not accessible publicaly	Y	The paper provides examples of specific queries that can be performed through the website that would normally require coding and integrating multiple data sources, but it is limited to knowledge extraction and does not show how this could be used to make novel biological discoveries	N	N	N	Y, coding free queries of human genomic information including both functional, strutural, epigenetic and other relationships 	Y	N	N	Kind of but not explicitly. Since this tool is all about data querying, confidence could be assesed by creating multiple queries like the example of using eQTLs to "validate" EnhancerAtlas relationships	Y	CC BY-NC 4.0
robokop	Y, can access subgraphs through query searches	Y	Y: neo4j, ExEmPLAR (experimental tool for queries of Neo4j graphs), website with "question builder" feature, automat queries (cypher and TRAPI)	Y	Y, can download or query searches in multiple ways	Y	Y, https://github.com/RobokopU24/ORION (this is not the original GH from the paper but is now the one they are using)	Y	Y, https://stars.renci.org/var/plater/graphs/RobokopKG/6fe13d850fdbf89c/	Y	Y, metadata contains all source info	Y	Y metadata includes links and versions for all sources	Y	Y, github lists docker requirements and graph spec file with example provided	Y	Y, node and edges contain primary knowledge source attribute and, if relationship is inferred, any algorithms/methods used	Y	not explicitly mentioned in paper or docs, but github for creating KG/metadata records have an "edge_normalization_version" so it appears they do	Y	"one-hop" connection schema has summary of all edge types (node 1 type, node 2 type, relationship), and individual edges include the original data source, but sources per triple type were not explicitly stated/summarized	N	"one-hop" connection schema has summary of all edge types, and individual edges include the original data source, but sources per edge type were not explicitly stated	N	Yes, json files	Y	Y, choose one external representative entity ID and map synonyms using existing equivalencies and specailized rules	Y	Y, github repo for construction with reaonsable documentation on how to use it in general, and metadata files include exact versions of functions that were used when creating their KG	Y	not explicitly described but metadata contains all preprocessing steps per source with versions of each normalization strategies used	Y	BioLink	Y	N	N	Y, github	Y	Contact form provided on website and weekly office hours over zoom	Y	N	N	accessible for bulk download. No chnage log, but each comes with metadata that documents all source ingests (including versions) and preprocessing steps used for each source	Y	Y, 4 ranging from simple linear queries to discovering mechanistic links	Y	N	N	N	N	N	N	Y, informative subgrahs are ranked according to number of supporting publications and literarure co-occurence of entity pairs	Y	Open-Source MIT License
embiology	N	N	N	N	N	N	N	N	N	N	N	N	N	N	N	N	N	N	N	N	N	N	Y, changed yearly in their baseline updated but cannot see what schema is without paid account	Y	N	N	Not explicitly stated but they use ML for entity recognition  so probably	N	N	N	N, lots of this is based on NLP/text mining approaches but preprocessing of sources is not documented	N	N	N	N	N	N	N	Contact form (for sales team)	Y	Y, cannot confirm but website states yearly update of terminology/rules, quarterly update of clinical trial data, weekly update of relationships extracted from publications	Y	N	N	N	N	N	N	Not clearly stated but appears to be drug discovery for private companies	N	N	N	Confidence thresholds for relationships determined by number of supporting publications	Y	Copyrighted to Elsevier
drugmechdb	Y, paths that describe the mechanism of action for drug/disease indication pair	Y	website, can view all paths or only those related to a specific drug or disease	Y	Y Can download from zenodo or use website	Y	Y: https://github.com/SuLab/DrugMechDB	Y	Kind of on zenodo, but what they are calling a KG is a collection of entries for drug/disease pairs and the paths connecting them. Raw KG containing all edges between all entries does not appear to exist	Y	table with node sources. Indications: DrugCentral ( according to GH, randomly sampled from availble drug-disease pairs, does not include all of them), paths: Mechanism of Action section from DrugBank, description section within Inxight Drugs, review articles, GeneOntology , UniProt, Reactome, and well-sources Wikipedia articles. No Primary experimental results are included. All are verified by curators	Y	Date given for DrugCentral download, cannot find info for other sources	N	Y, there are requirements.txt and .yaml files in the KG's downloadable .zip file on Zenodo (https://zenodo.org/records/8139357) showing the dependencies.	Y	each entry consist of ‘graph’, ‘links’, ‘nodes’, and ‘reference’ keys. Graph contains the drug/disease pair, links contains relationships informative to the indication, nodes contains information about all entities in link, and reference contains all the sources for the entire relationship but not specifically for individual nodes/edges	Y	paths are manually curated 	N	edges between informative nodes in a path do not contain orignal source infromation. Informative paths have citations for the entire path, not indivudal triples within them. 	N	BioLink, but does not specify exactly what sources are used for each edge type	Y	yes, json files	Y	yes, all nodes come from existing sources	Y	Not really. Everything is "manually curated"	N	N	N	BioLink	Y	Y	Y	GitHub Issues. Also includes a guide for how users can submit their own curated paths.  	Y	indirectly. website indicated the lab who owns it, but does not provide a point of contact	Y	N (V1 released in 2019 with one update less than a year later, same with V2 in 2023, no other updates)	N	All versions availble, V2 has publication associated but detailed change logs for minor updates not available	N	N	N	They used an external KG to evaluate agreement between types of associations present in both graphs and calculate a p-value representing when the simulated percentage of matching was greater than or equal to the observed percentage	Y	Yes, mechanisms of action by which a drug treats a disease	Y	N	N	agreement with MechRepoNet	Y	CC0 1.0 Universal